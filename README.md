Использованные данные: https://www.finam.ru/profile/otrasli-ehkonomiki-usa/health-care/export/?market=27&em=18984&token=&code=%24DJUSHC&apply=0&df=12&mf=0&yf=2023&from=12.01.2023&dt=19&mt=0&yt=2023&to=19.01.2023&p=3&f=%24DJUSHC_230112_230119&e=.txt&cn=%24DJUSHC&dtf=1&tmf=1&MSOR=1&mstime=on&mstimever=1&sep=1&sep2=1&datf=1&at=1

Примененные настройки для скачивания данных:
![image](https://user-images.githubusercontent.com/110770366/213873640-8141ecce-778d-4633-af85-1e0c9983c609.png)

Временной  ряд  представляет  собой  последовательность  наблюдений  за изменениями  во  времени  значений  параметров  некоторого  объекта  или процесса.  Строго  говоря,  каждый  процесс  непрерывен  во  времени,  то  есть некоторые  значения  параметров  этого  процесса  существуют  в  любой  момент времени. Но для задач анализа не нужно знать значения параметров объектов в любой момент времени. Интерес представляют временные отсчеты – значения зафиксированные  в  некоторые,  обычно равноотстоящие  моменты  времени. Отсчеты могут браться через различные промежутки: через минуту, час, день, неделю, месяц или год – в зависимости от того, насколько детально должен быть проанализирован процесс. В задачах анализа временных рядов мы имеем дело с дискретным  временем,  когда  каждое  наблюдение  за  параметром  образуют временной отсчет. Все временные отсчеты нумеруются в порядке возрастания. Тогда временной ряд будет представлен в следующем виде: X={x1, x2, …, xn}. 

LSTM – сети долгой краткосрочной памяти

Долгая краткосрочная память (англ. Long short-term memory, LSTM) — особая разновидность архитектуры рекуррентных нейронных сетей, способная к обучению долговременным зависимостям, предложенная в 1997 году Сеппом Хохрайтером и Юргеном Шмидхубером.

Рекуррентные нейронные сети добавляют память к искуственным нейронным сетям, но реализуемая память получается короткой — на каждом шаге обучения информация в памяти смешивается с новой и через несколько итераций полностью перезаписывается.

LSTM-модули разработаны специально, чтобы избежать проблемы долговременной зависимости, запоминая значения как на короткие, так и на длинные промежутки времени. Это объясняется тем, что LSTM-модуль не использует функцию активации внутри своих рекуррентных компонентов. Таким образом, хранимое значение не размывается во времени и градиент не исчезает при использовании метода обратного распространения ошибки во времени (англ. Backpropagation Through Time, BPTT)[2][3] при тренировке сети.

Ключевые компоненты LSTM-модуля: состояние ячейки и различные фильтры. О состоянии ячейки можно говорить, как о памяти сети, которая передает соответствующую информацию по всей цепочке модулей. Таким образом, даже информация из ранних временных шагов может быть получена на более поздних, нивелируя эффект кратковременной памяти.

![image](https://user-images.githubusercontent.com/110770366/213873972-8285247e-8f8b-45fb-bed2-e753d39d7139.png)

